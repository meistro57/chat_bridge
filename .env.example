# Copy this file to .env and fill in your actual API keys

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Anthropic API Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Google/Gemini API Configuration
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_API_KEY=your_google_api_key_here  # Alternative name used in some scripts
GOOGLE_MODEL=gemini-2.5-flash

# DeepSeek API Configuration
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat

# OpenRouter API Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=openai/gpt-4o-mini
# Optional: Customize app name shown in OpenRouter logs
OPENROUTER_APP_NAME=Chat Bridge
OPENROUTER_REFERER=https://github.com/yourusername/chat-bridge

# Optional: Bridge-specific overrides
# BRIDGE_PROVIDER_A=openai
# BRIDGE_PROVIDER_B=anthropic
# BRIDGE_MODEL_A=gpt-4o-mini
# BRIDGE_MODEL_B=claude-3-5-sonnet-20241022
# BRIDGE_SYSTEM_A="Custom system prompt for agent A"
# BRIDGE_SYSTEM_B="Custom system prompt for agent B"

# Optional: Local model endpoints
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODEL=llama3.1:8b-instruct
# LMSTUDIO_BASE_URL=http://localhost:1234/v1
# LMSTUDIO_MODEL=lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF